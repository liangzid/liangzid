

<h1 align="center">Hi, I'm Zi Liang (梁 子) 👋</h1>

<p align="center">
  Ph.D. student at <b>The Hong Kong Polytechnic University</b><br/>
  Researching LLMs, Security, Privacy, and Alignment
</p>

<p align="center">
  <a href="https://liangzid.github.io/research.html"><img src="https://img.shields.io/badge/Research-Homepage-blue?logo=google-scholar" /></a>
  <a href="mailto:zi1415926.liang@connect.polyu.hk"><img src="https://img.shields.io/badge/Email-Contact-red?logo=gmail" /></a>
</p>

---

## 🔬 Research Interests

>  I specialize in analyzing the potential risks inherent in language models, with a focus on **understanding why and how neural networks function and identifying vulnerabilities within them**. My research is driven by a deep **curiosity to uncover the mechanisms behind these models and to address the security challenges they present**.

> My work can be categorized into two main areas:

> 1. Uncovering New Threats and Developing Defenses: I conduct comprehensive evaluations of popular AI services and techniques, combining in-depth theoretical analysis with practical experimentation.
> 2. Enhancing Understanding of Models and Learning Processes: I aim to explain the root causes of safety issues in AI systems, examining how these problems arise during model training and inference, and what they imply for the broader field of machine learning.

> In addition to my research, I have extensive experience in natural language processing (NLP), particularly in building conversational AI systems, which I have been actively involved in since 2019. More recently, starting in 2024, I have developed a strong interest in the future of AI, particularly in the application of reinforcement learning (RL) to advance the capabilities and safety of intelligent systems. 


## 🔬 Recent Studies

| Project | Venue | Tags | Description |
|--------|--------|------|-------------|
| 🚨 [**LoRA-sSecurity**](https://github.com/liangzid/LoRA-sSecurity) | ICML'25 | ![](https://img.shields.io/badge/LoRA-red) ![](https://img.shields.io/badge/Attack-orange) | Explores vulnerabilities introduced by LoRA-based fine-tuning, proposing both theoretical analysis and practical attacks. |
| 🧠 [**LoRD-MEA**](https://github.com/liangzid/LoRD-MEA) | ACL'25 | ![](https://img.shields.io/badge/Model%20Extraction-blue) ![](https://img.shields.io/badge/RL-green) | Proposes an RL-based model extraction attack tailored for alignment-aware LLMs. |
| 🕵️‍♂️ [**PromptExtractionEval**](https://github.com/liangzid/PromptExtractionEval) | Preprint | ![](https://img.shields.io/badge/Prompt%20Leakage-yellow) ![](https://img.shields.io/badge/Evaluation-lightgrey) | Analyzes why your prompts get leaked and proposes practical defenses. |
| 🔐 [**MERGE**](https://github.com/liangzid/MERGE) | AAAI'24 | ![](https://img.shields.io/badge/MPC-purple) ![](https://img.shields.io/badge/HE-blueviolet) | Lightweight MPC + HE framework for privacy-preserving, fast text generation in real-world scenarios. |
| ⚖️ [**ISAAC**](https://github.com/liangzid/ISAAC) | AAAI'25 | ![](https://img.shields.io/badge/Alignment-brown) ![](https://img.shields.io/badge/CorpusAnalysis-teal) | Investigates implicit alignment signals in training corpora and their influence on downstream tuning. |

---

## 🚀 Open Source Projects

| Project | Description |
|--------|-------------|
| 🧪 [**zhouyi**](https://github.com/liangzid/zhouyi) | A playful and philosophical implementation of divination using the ancient Chinese classic *Zhouyi* (易经). Reflects a blend of symbolic computation, randomness, and interpretation. |
| 🔧 [**easy-collections**](https://github.com/liangzid/easy-collections) | - |

---

## 📊 GitHub Analytics

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=liangzid&show_icons=true&theme=tokyonight" width="48%" />
  

---

<p align="center">
  <img src="https://github-readme-streak-stats.herokuapp.com?user=liangzid&theme=tokyonight" width="48%" />
</p>


---


<p align="center">
  <a href="https://liangzid.github.io/research.html">
    <img src="https://img.shields.io/badge/Visit-My Research Page-blue?style=for-the-badge&logo=github" />
  </a>
</p>

---

<p align="center">
  <sub><i>🧠 This README is automatically generated by <b>GPT-4o</b> and manually refined by Zi Liang.</i></sub>
</p>
